{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Data in Python\n",
    "The examples and code in this notebook are made by [Jean-Nicholas Hould](http://www.jeannicholashould.com/)\n",
    "\n",
    "Detailed explanations for important code snippets are provided by Mervat Abuelkheir as part of the CSEN1095 Data Engineering Course.\n",
    "\n",
    "The goal of this notebook is to show how a messy dataset can be tidied into proper rows representing objects, columns representing attributes, and cells representing scalar values.\n",
    "\n",
    "Pay attention to the <span style=\"color:red\"> <b> paragraphs in bold red</b></span>; they ask you to do something and provide input!\n",
    "\n",
    "First thing we need to do is import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime # to handle date/time attributes\n",
    "from os import listdir # os is a module for interacting with the OS\n",
    "from os.path import isfile, join # to verify file object, and concatenate paths\n",
    "import glob # to find pathnames matching a specific pattern\n",
    "import re # regular expressions :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the datasets\n",
    "\n",
    "In this part of the exercise we will import a number of datasets and examine their structure to verify if the datasets are tidy.\n",
    "\n",
    "Remember the requirements for a tidy dataset:\n",
    "<br> 1- Each row describes a single object\n",
    "<br> 2- Each column describes a property/attribute of that object\n",
    "<br> 3- Column values have the same measurement unit\n",
    "<br> 4- Columns contain atomic/scalar values (no multiple values per table cell)\n",
    "\n",
    "For each dataset imported, test your ability to identify is it is tidy or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: Pew Research Center\n",
    "\n",
    "Pew Research Center is a famous center in the US that performs polling surveys on citizens. This is example data about the breakdown of yearly income per religion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/pew-raw.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> <b> What are the attributes of interest? How are they organized? Is the dataset tidy? </b></span> \n",
    "    \n",
    "You can brainstorm your thought process and document in a new cell if you like.\n",
    "<br>Instructions for beginners:\n",
    "<br>- Add a new cell from the notebook menu above (+ button).\n",
    "<br>- Double click anywhere inside the new cell to enter edit mode.\n",
    "<br>- When done, press CTRL+ENTER or SHIFT+ENTER to commit content.\n",
    "<br>- You can edit content anytime by double clicking inside the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's tidy the dataset!\n",
    "\n",
    "The melt function is used to change the format of a pandas data frame from wide to long, assigning one column as an identifier and \"unpivoting\" the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# melt method takes as input a dataframe, one or more identifier attributes, one or more attribute names, and value attribute \n",
    "# define new pandas dataframe, religion column will be identifier attribute\n",
    "# values spread across multiple column headers of income ranges will be unpivoted into new attribute \"income\"\n",
    "# actual frequencies of citizens with specific income range will be unpivoted into new attribute \"freq\"\n",
    "formatted_df = pd.melt(df,[\"religion\"], var_name=\"income\", value_name=\"freq\")\n",
    "formatted_df = formatted_df.sort_values(by=[\"religion\"]) # just sorting the new table by religion attribute\n",
    "formatted_df.head(10) # show first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> <b> Why do the indices that are added automatically by pandas appear out of order? </b></span> \n",
    "<br>(Just a question to let you think of how pandas dataframes are indexed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: Billboard Top 100\n",
    "\n",
    "This dataset outlines data about the top hit songs on the Billboard list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/billboard.csv\", encoding=\"mac_latin2\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> <b> Again: What are the attributes of interest? How are they organized? Is the dataset tidy? </b></span>\n",
    "\n",
    "The structure of the dataset is more complex than the previous one, and it is not immediately clear what a typical row should represent or look like. Answering the above questions helps you frame the data better. \n",
    "<br>You can brainstorm your thought process and document in a new cell if you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's tidy the dataset!\n",
    "\n",
    "One way a record could be organized is to make it represent the rank of each song in every week the song was on the Billboard list. This omits the need to keep track of all 76 weeks data, which is null for most of the songs.\n",
    "\n",
    "A record would have data about the year, artist, track, time, genre, week, rank, and date.\n",
    "\n",
    "The unique identifier is no single attribute, as one artist can have the track on the billboards at the same year, genre, and time. The only difference would be the week, rank, and date (since date is correlated with week). Therefore, to identify a track's rank and week, we need to use the year, artist, track, time, genre, and date as a combined unique identifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Note on conversions in Python</span>\n",
    "\n",
    "<span style=\"color:blue\"> The following conversions are accepted by Python:</span>\n",
    "<br><span style=\"color:blue\"> - passing a string representation of an integer into int</span>\n",
    "<br><span style=\"color:blue\"> - passing a string representation of a float into float</span>\n",
    "<br><span style=\"color:blue\"> - passing a string representation of an integer into float</span>\n",
    "<br><span style=\"color:blue\"> - passing an integer into float</span>\n",
    "<br><span style=\"color:blue\"> - passing a float into int</span>\n",
    "\n",
    "<span style=\"color:blue\"> You get an error if you pass a string representation of a float (or anything other than an integer) into int</span>\n",
    "<br><span style=\"color:blue\"> This is especially problematic if you have NaN values that are float and you want to convert them to integers. It does not work using int, and you have to use Int32. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to tidying up the Billboard dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting\n",
    "# Define unique identifiers in one variable. Include both dates of entry and peak for now; will be merged into one attribute later.\n",
    "id_vars = [\"year\",\"artist.inverted\",\"track\",\"time\",\"genre\",\"date.entered\",\"date.peaked\"]\n",
    "# Now melt structure to have identifiers, variable name (week) and values (rank)\n",
    "df = pd.melt(frame=df,id_vars=id_vars, var_name=\"week\", value_name=\"rank\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting \n",
    "# First, for week attribute, extract week number from string representation of week column names and convert to float then to integer\n",
    "df[\"week\"] = df[\"week\"].str.extract('(\\d+)', expand=False).astype(float).astype(int) \n",
    "# Second, extract rank values and convert them to integer\n",
    "df[\"rank\"] = df[\"rank\"].astype('Int32')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning out unnecessary rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Create \"date\" columns\n",
    "# Date for each week is date the track entered the billboard + number of weeks passed for an entry\n",
    "# Example: if date entered is 26/02/2000, then this is the date for week 1, and the date will change for week 2 to become 04/03/2000, and so on\n",
    "df[\"date\"] = pd.to_datetime(df[\"date.entered\"]) + pd.to_timedelta(df[\"week\"], unit='w') - pd.DateOffset(weeks=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame the final tidy data, replacing the dates of entry and peak with only the date, then sort by the identifiers\n",
    "final_df = df[[\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\", \"week\", \"rank\", \"date\"]]\n",
    "final_df = final_df.sort_values(ascending=True, by=[\"year\",\"artist.inverted\",\"track\",\"week\",\"rank\"])\n",
    "\n",
    "# Assigning the tidy dataset to a variable for future usage\n",
    "billboard = final_df\n",
    "billboard.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>Why did we convert the week string to float before converting it to int?</b></span>\n",
    "\n",
    "<span style=\"color:red\"><b>What does the parameter '(\\d+)' in the string.extract method do? </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check the tidied data frame\n",
    "# Separating this line of code to avoid running the formatting code multiple times and getting errors\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3: Tubercolosis\n",
    "\n",
    "This dataset outlines the number of tubercolosis patients in different countries in the year 2000.\n",
    "\n",
    "A few notes on the raw data set:\n",
    "\n",
    "- The columns starting with \"m\" or \"f\" contain multiple variables: \n",
    "    - Sex (\"m\" or \"f\")\n",
    "    - Age Group (\"0-14\",\"15-24\", \"25-34\", \"45-54\", \"55-64\", \"65\", \"unknown\")\n",
    "- Mixture of 0s and missing values(\"NaN\"). This is due to the data collection process and the distinction is important for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tb-raw.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> <b> Again: What are the attributes of interest? How are they organized? Is the dataset tidy? </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's tidy the dataset!\n",
    "\n",
    "Same as what we did before: We need identifiers, we need the column names to represent variables (two in this case, since the column names carry information about gender and age group), and we need the frequency values to be in one column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the year and country as unique identifiers, and name the # of patients as \"cases\" and the column variables as \"sex and age\"\n",
    "df = pd.melt(df, id_vars=[\"country\",\"year\"], value_name=\"cases\", var_name=\"sex_and_age\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Sex, Age lower bound and Age upper bound group\n",
    "tmp_df = df[\"sex_and_age\"].str.extract(\"(\\D)(\\d+)(\\d{2})\", expand=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df now has multiple columns corresponding to the strings extracted from the column names. Now name the columns\n",
    "tmp_df.columns = [\"sex\", \"age_lower\", \"age_upper\"]\n",
    "\n",
    "# Create \"age\" column based on \"age_lower\" and \"age_upper\"\n",
    "tmp_df[\"age\"] = tmp_df[\"age_lower\"] + \"-\" + tmp_df[\"age_upper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge - axis parameter indicates the axis along which merge will take place. 1 means by columns\n",
    "df = pd.concat([df, tmp_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns and rows\n",
    "df = df.drop(['sex_and_age',\"age_lower\",\"age_upper\"], axis=1)\n",
    "# Drop null values\n",
    "df = df.dropna()\n",
    "# Sort rows by all four attributes\n",
    "df = df.sort_values(ascending=True,by=[\"country\", \"year\", \"sex\", \"age\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>What does the parameter value \"(\\D)(\\d+)(\\d{2})\" do?</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4: Global Historical Climatology Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/weather-raw.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, variables are stored in both rows and columns. tmax and tmin stand for max and min temperatures for each day. Date is broken down to three columns, with the day being spread across multiple columns. We need the data to represent min and max temperatures per date.\n",
    "\n",
    "Notice that the dataset has many missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's tidy the dataset!\n",
    "\n",
    "Same as what we did before: We need identifiers, we need the column names to represent variables (min and max, and date!), and we need the temperature values to be in two columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start first by putting the day values in one column. We will not play with min and max temperatures for now\n",
    "df = pd.melt(df, id_vars=[\"id\", \"year\",\"month\",\"element\"], var_name=\"day_raw\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting day\n",
    "# df[\"day\"] automatically adds a \"day\" attribute to the df dataframe\n",
    "df[\"day\"] = df[\"day_raw\"].str.extract(\"d(\\d+)\", expand=False)  \n",
    "df[\"id\"] = \"MX17004\"\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year, month, and day to numeric values\n",
    "# Notice the use of the lamda function to apply one instruction to multiple inputs\n",
    "df[[\"year\",\"month\",\"day\"]] = df[[\"year\",\"month\",\"day\"]].apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to create a date from the different columns. \n",
    "# Function accepts a row of 3 values as input and returns consolidated date\n",
    "def create_date_from_year_month_day(row):\n",
    "    return datetime.datetime(year=row[\"year\"], month=int(row[\"month\"]), day=row[\"day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date attribute, by having the temporary lamda function call the create_date function\n",
    "df[\"date\"] = df.apply(lambda row: create_date_from_year_month_day(row), axis=1)\n",
    "# Drop the redundant columns used to compute date\n",
    "df = df.drop(['year',\"month\",\"day\", \"day_raw\"], axis=1)\n",
    "# Now drop the missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmelting column \"element\"\n",
    "df = df.pivot_table(index=[\"id\",\"date\"], columns=\"element\", values=\"value\")\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Exercise your tidying muscles! </span>\n",
    "\n",
    "<span style=\"color:red\"><b> The GapMinder dataset includes information about the life expectancy, the GDP per capita, and the population of various countries between the years 1952 and 2007.</b></span>\n",
    "\n",
    "<span style=\"color:red\"> <b>Import the dataset, investigate it to identify what the potential attributes should be, the problems with the current structure, and think of how to tidy the dataset, and then proceed to tidy the dataset.</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>gdpPercap_1952</th>\n",
       "      <th>gdpPercap_1957</th>\n",
       "      <th>gdpPercap_1962</th>\n",
       "      <th>gdpPercap_1967</th>\n",
       "      <th>gdpPercap_1972</th>\n",
       "      <th>gdpPercap_1977</th>\n",
       "      <th>gdpPercap_1982</th>\n",
       "      <th>gdpPercap_1987</th>\n",
       "      <th>...</th>\n",
       "      <th>pop_1962</th>\n",
       "      <th>pop_1967</th>\n",
       "      <th>pop_1972</th>\n",
       "      <th>pop_1977</th>\n",
       "      <th>pop_1982</th>\n",
       "      <th>pop_1987</th>\n",
       "      <th>pop_1992</th>\n",
       "      <th>pop_1997</th>\n",
       "      <th>pop_2002</th>\n",
       "      <th>pop_2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2449.008185</td>\n",
       "      <td>3013.976023</td>\n",
       "      <td>2550.816880</td>\n",
       "      <td>3246.991771</td>\n",
       "      <td>4182.663766</td>\n",
       "      <td>4910.416756</td>\n",
       "      <td>5745.160213</td>\n",
       "      <td>5681.358539</td>\n",
       "      <td>...</td>\n",
       "      <td>11000948.0</td>\n",
       "      <td>12760499.0</td>\n",
       "      <td>14760787.0</td>\n",
       "      <td>17152804.0</td>\n",
       "      <td>20033753.0</td>\n",
       "      <td>23254956.0</td>\n",
       "      <td>26298373.0</td>\n",
       "      <td>29072015.0</td>\n",
       "      <td>31287142</td>\n",
       "      <td>33333216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Angola</td>\n",
       "      <td>3520.610273</td>\n",
       "      <td>3827.940465</td>\n",
       "      <td>4269.276742</td>\n",
       "      <td>5522.776375</td>\n",
       "      <td>5473.288005</td>\n",
       "      <td>3008.647355</td>\n",
       "      <td>2756.953672</td>\n",
       "      <td>2430.208311</td>\n",
       "      <td>...</td>\n",
       "      <td>4826015.0</td>\n",
       "      <td>5247469.0</td>\n",
       "      <td>5894858.0</td>\n",
       "      <td>6162675.0</td>\n",
       "      <td>7016384.0</td>\n",
       "      <td>7874230.0</td>\n",
       "      <td>8735988.0</td>\n",
       "      <td>9875024.0</td>\n",
       "      <td>10866106</td>\n",
       "      <td>12420476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Benin</td>\n",
       "      <td>1062.752200</td>\n",
       "      <td>959.601080</td>\n",
       "      <td>949.499064</td>\n",
       "      <td>1035.831411</td>\n",
       "      <td>1085.796879</td>\n",
       "      <td>1029.161251</td>\n",
       "      <td>1277.897616</td>\n",
       "      <td>1225.856010</td>\n",
       "      <td>...</td>\n",
       "      <td>2151895.0</td>\n",
       "      <td>2427334.0</td>\n",
       "      <td>2761407.0</td>\n",
       "      <td>3168267.0</td>\n",
       "      <td>3641603.0</td>\n",
       "      <td>4243788.0</td>\n",
       "      <td>4981671.0</td>\n",
       "      <td>6066080.0</td>\n",
       "      <td>7026113</td>\n",
       "      <td>8078314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  continent  country  gdpPercap_1952  gdpPercap_1957  gdpPercap_1962  \\\n",
       "0    Africa  Algeria     2449.008185     3013.976023     2550.816880   \n",
       "1    Africa   Angola     3520.610273     3827.940465     4269.276742   \n",
       "2    Africa    Benin     1062.752200      959.601080      949.499064   \n",
       "\n",
       "   gdpPercap_1967  gdpPercap_1972  gdpPercap_1977  gdpPercap_1982  \\\n",
       "0     3246.991771     4182.663766     4910.416756     5745.160213   \n",
       "1     5522.776375     5473.288005     3008.647355     2756.953672   \n",
       "2     1035.831411     1085.796879     1029.161251     1277.897616   \n",
       "\n",
       "   gdpPercap_1987  ...    pop_1962    pop_1967    pop_1972    pop_1977  \\\n",
       "0     5681.358539  ...  11000948.0  12760499.0  14760787.0  17152804.0   \n",
       "1     2430.208311  ...   4826015.0   5247469.0   5894858.0   6162675.0   \n",
       "2     1225.856010  ...   2151895.0   2427334.0   2761407.0   3168267.0   \n",
       "\n",
       "     pop_1982    pop_1987    pop_1992    pop_1997  pop_2002  pop_2007  \n",
       "0  20033753.0  23254956.0  26298373.0  29072015.0  31287142  33333216  \n",
       "1   7016384.0   7874230.0   8735988.0   9875024.0  10866106  12420476  \n",
       "2   3641603.0   4243788.0   4981671.0   6066080.0   7026113   8078314  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/gapminder.csv\") \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['gdpPercap', 'lifeExp', 'pop']\n",
    "col_dict = {\n",
    "    # KayAI Check\n",
    "    'gdpPercap': None, \n",
    "    'lifeExp': None, \n",
    "    'pop': None\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_cols:\n",
    "    col_dict[col] = pd.concat([df.loc[:, 'continent':'country'], \n",
    "                               df.loc[:, f'{col}_1952':f'{col}_2007']], axis=1) \n",
    "    col_dict[col] = col_dict[col].melt(id_vars=[\"continent\", \"country\"], \n",
    "                                       var_name=\"year\", value_name=f'{col}')\n",
    "    col_dict[col]['year'] = col_dict[col]['year'].str.replace(r'\\D', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gapminder_df = pd.concat([col_dict[new_cols[0]], \n",
    "                              col_dict[new_cols[1]][new_cols[1]], \n",
    "                              col_dict[new_cols[2]][new_cols[2]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1952</td>\n",
       "      <td>2449.008185</td>\n",
       "      <td>43.077</td>\n",
       "      <td>9279525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1952</td>\n",
       "      <td>3520.610273</td>\n",
       "      <td>30.015</td>\n",
       "      <td>4232095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Benin</td>\n",
       "      <td>1952</td>\n",
       "      <td>1062.752200</td>\n",
       "      <td>38.223</td>\n",
       "      <td>1738315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>1952</td>\n",
       "      <td>851.241141</td>\n",
       "      <td>47.622</td>\n",
       "      <td>442308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>1952</td>\n",
       "      <td>543.255241</td>\n",
       "      <td>31.975</td>\n",
       "      <td>4469979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1699</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2007</td>\n",
       "      <td>37506.419070</td>\n",
       "      <td>81.701</td>\n",
       "      <td>7554661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2007</td>\n",
       "      <td>8458.276384</td>\n",
       "      <td>71.777</td>\n",
       "      <td>71158647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1701</td>\n",
       "      <td>Europe</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2007</td>\n",
       "      <td>33203.261280</td>\n",
       "      <td>79.425</td>\n",
       "      <td>60776238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1702</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2007</td>\n",
       "      <td>34435.367440</td>\n",
       "      <td>81.235</td>\n",
       "      <td>20434176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1703</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2007</td>\n",
       "      <td>25185.009110</td>\n",
       "      <td>80.204</td>\n",
       "      <td>4115771.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     continent         country  year     gdpPercap  lifeExp         pop\n",
       "0       Africa         Algeria  1952   2449.008185   43.077   9279525.0\n",
       "1       Africa          Angola  1952   3520.610273   30.015   4232095.0\n",
       "2       Africa           Benin  1952   1062.752200   38.223   1738315.0\n",
       "3       Africa        Botswana  1952    851.241141   47.622    442308.0\n",
       "4       Africa    Burkina Faso  1952    543.255241   31.975   4469979.0\n",
       "...        ...             ...   ...           ...      ...         ...\n",
       "1699    Europe     Switzerland  2007  37506.419070   81.701   7554661.0\n",
       "1700    Europe          Turkey  2007   8458.276384   71.777  71158647.0\n",
       "1701    Europe  United Kingdom  2007  33203.261280   79.425  60776238.0\n",
       "1702   Oceania       Australia  2007  34435.367440   81.235  20434176.0\n",
       "1703   Oceania     New Zealand  2007  25185.009110   80.204   4115771.0\n",
       "\n",
       "[1704 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gapminder_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
